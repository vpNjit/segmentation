{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b2446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.main import *\n",
    "from mrcnn.utils import *\n",
    "# Set path to Mask RCNN folder\n",
    "ROOT_DIR = os.path.abspath(\"C:/TEMP/MaskRCNN\")\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline \n",
    "from mrcnn.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f83363",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'C:/TEMP/Mask-R-CNN/V3/Mask_RCNN/logs/cell20180618T0605/mask_rcnn_cell_0040.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a26a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(CellConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    IMAGE_RESIZE_MODE = \"pad64\" # 'none' #\n",
    "    DETECTION_MAX_INSTANCES = 3500 #3000\n",
    "    DETECTION_MIN_CONFIDENCE = 0.7\n",
    "    DETECTION_NMS_THRESHOLD = 0.20\n",
    "    #ROI_POSITIVE_RATIO = 0.8\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
    "    #MEAN_PIXEL = np.array([40,15,30])\n",
    "    \n",
    "    POST_NMS_ROIS_INFERENCE=12000 #15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a53785",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig()\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2192d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = sorted(glob.glob('./train/*crop.png'))\n",
    "train_masks = sorted(glob.glob('./train/*label.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89d149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_index=0\n",
    "im = imageio.imread(train_images[example_index])\n",
    "r = model.detect([im], verbose=1)[0]\n",
    "plt.figure(figsize=(20,5),dpi=100)\n",
    "ax1=plt.subplot(1,4,1)\n",
    "plt.imshow(im)\n",
    "plt.title('Input Image')\n",
    "plt.axis('off')\n",
    "ax2=plt.subplot(1,4,2)\n",
    "visualize.display_instances_new(im, r['rois'], r['masks'], r['class_ids'], r['scores'], ax=ax2)\n",
    "plt.title('Prediction overlap with input')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,4,3)\n",
    "mask = np.zeros(im.shape[:2])\n",
    "for x in range(r['masks'].shape[2]):\n",
    "    mask+= (r['masks'][:,:,x])\n",
    "plt.imshow(mask>0)\n",
    "plt.title('Output Mask')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(imageio.imread(train_masks[example_index]))\n",
    "plt.title('Groundtruth')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53843593",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = sorted(glob.glob('./data/RGB_2/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eaccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "for image in test_images:\n",
    "    plt.figure(figsize=(20,10),dpi=100)\n",
    "    im = imageio.imread(image)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(im)\n",
    "    ax2=plt.subplot(1,2,2)\n",
    "    r=results = model.detect([im], verbose=1)[0]\n",
    "    visualize.display_instances_new(im, r['rois'], r['masks'], r['class_ids'], r['scores'], ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b3dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'C:/TEMP/MaskRCNN/data/segmentation/'\n",
    "rgb_images = sorted(glob.glob('C:/TEMP/MaskRCNN/data/RGB_2/*.png')) \n",
    "rgb_images_colormap2 = sorted(glob.glob('./data/RGB_2/*.png')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a93f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## unit prediction image size\n",
    "x_size = 512 #512\n",
    "y_size=704 #704\n",
    "\n",
    "to_output_image = True\n",
    "for e,in_image in enumerate(rgb_images):\n",
    "    out_image = '.'.join('/'.join(in_image.split('/')[-2:]).split('.')[:-1])\n",
    "    os.makedirs(os.path.dirname(output_dir+out_image), exist_ok=True)\n",
    "    test_image = imageio.imread(in_image)\n",
    "    test_image_ori = imageio.imread(rgb_images_colormap2[e])\n",
    "\n",
    "    test_x_offset = 0\n",
    "    test_y_offset = 0\n",
    "    imagesize= test_image.shape\n",
    "\n",
    "    x_size = 512 #512\n",
    "    y_size=704 #704\n",
    "    x_patch = imagesize[0]//x_size +1\n",
    "    y_patch = imagesize[1]//y_size +1\n",
    "\n",
    "    height, width = test_image.shape[:2]\n",
    "    whole_img = np.zeros([height,width,3])\n",
    "    score_mask = []\n",
    "    sub_id=1\n",
    "    mask_name = output_dir+out_image+'.txt'\n",
    "    score_name = output_dir+out_image+'_score.txt'\n",
    "    openwrite = open(mask_name, 'w+')\n",
    "    openscore = open(score_name, 'w+')\n",
    "    openwrite.writelines(str(height)+','+str(width)+'\\n')\n",
    "    for i in range(x_patch):\n",
    "        for j in range(y_patch):\n",
    "            real_mask=[]\n",
    "\n",
    "            test_x_offset = x_size*i\n",
    "            test_y_offset = y_size*j\n",
    "            test_image_rgb = test_image[test_x_offset:test_x_offset+x_size,test_y_offset:test_y_offset+y_size,:]\n",
    "\n",
    "            test_image_rgb_ori = test_image_ori[test_x_offset:test_x_offset+x_size,test_y_offset:test_y_offset+y_size,:]\n",
    "\n",
    "            r = model.detect([test_image_rgb], verbose=0)[0]\n",
    "\n",
    "            if to_output_image:\n",
    "                output_image = visualize.display_instances(test_image_rgb, r['rois'], r['masks'], r['class_ids'], r['scores'],show_bbox=None,figsize=(30, 30))\n",
    "                whole_img[test_x_offset:test_x_offset+output_image.shape[0],test_y_offset:test_y_offset+output_image.shape[1],:]=output_image\n",
    "\n",
    "            #print(test_image_rgb.shape,output_image.shape)\n",
    "            for index in range(r['masks'].shape[2]):\n",
    "                mask = r['masks'][:,:,index]\n",
    "                if np.sum(mask)<=25:\n",
    "                    continue\n",
    "                temp_mask = np.zeros([height,width])\n",
    "                temp_mask[test_x_offset:test_x_offset+test_image_rgb.shape[0],test_y_offset:test_y_offset+test_image_rgb.shape[1]]=mask\n",
    "                real_mask.append(temp_mask)\n",
    "                score_mask.append(r['scores'][index])\n",
    "            mask_image = output_dir+out_image+'-'+str(sub_id)+'.png'\n",
    "            visualize.save_instances(test_image_rgb_ori, r['rois'], r['masks'], r['class_ids'],class_names=['BG', 'cell'],title=mask_image,show_bbox=None,show_mask=None)\n",
    "            sub_id+=1\n",
    "            if len(real_mask)!=0:\n",
    "                real_mask=np.asarray(real_mask) #.swapaxes(1,2).T\n",
    "                x=mask_to_rle_overlap(e, (real_mask))\n",
    "                openwrite.writelines(x + '\\n')\n",
    "\n",
    "    np.savetxt(openscore, np.array(score_mask), delimiter=\",\")\n",
    "\n",
    "    openwrite.close()\n",
    "    openscore.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
